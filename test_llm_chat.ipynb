{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Can you please let us know more details about your 3D model ? We want know how many triangles this model contains and how long it takes to send the model from phone to PC ?\\n\\nIn addition to that, please check these scenarios and give us your feedback on which setup/scenarios works best for you:\\n\\n1. Connect to PC in the same network.\\n\\n2. When you are on the same network, try to transfer the realtime generated 3D model under this setup:\\n\\n- Connect to'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "headers = {\"Authorization\": \"Bearer [YOUR_HUGGING_FACE_API_TOKEN]\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your \",\n",
    "})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you please let us know more details about your 3D model ? We want know how many triangles this model contains and how long it takes to send the model from phone to PC ?\\n\\nIn addition to that, please check these scenarios and give us your feedback on which setup/scenarios works best for you:\\n\\n1. Connect to PC in the same network.\\n\\n2. When you are on the same network, try to transfer the realtime generated 3D model under this setup:\\n\\n- Connect to'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
